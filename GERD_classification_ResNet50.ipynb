{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Copy of GERD_classification_VGG16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMJHoVdOK8ioq3FNWX7rnSs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qQaVgHtejA8o"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTexpkytd90d"},"source":["%cd '../GERD_data_1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSXzuK2CjaSX"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","import sklearn\n","import random\n","import tensorflow as tf\n","import os\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D52QuA-5jeH-"},"source":["base_path = '../GERD_data_1'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Mx1Hze6kMwi"},"source":["labels = ['GERD_A', 'GERD_B']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrkdqg4Bkk0u"},"source":["BATCH_SIZE = 32\n","VERBOSE = 1\n","IMAGE_SIZE = 224"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wlgn58BzkpgY"},"source":["# Dataset from the training folder.\n","x_train=[]\n","y_train=[]\n","for i in labels:\n","    folderPath = os.path.join(os.path.join(base_path,'train'),i)\n","    for j in tqdm(os.listdir(folderPath)):\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n","        x_train.append(img)\n","        y_train.append(i)\n","print('Training dataset Loading complete.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPiUNB9Pk7Ig"},"source":["# Dataset from the testing folder..\n","x_test = []\n","y_test = []\n","for i in labels:\n","    folderPath = os.path.join(os.path.join(base_path,'test'),i)\n","    for j in tqdm(os.listdir(folderPath)):\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n","        x_test.append(img)\n","        y_test.append(i)\n","x_train = np.array(x_train)\n","y_train = np.array(y_train)\n","x_test = np.array(x_test)\n","y_test = np.array(y_test)\n","x_train, y_train = sklearn.utils.shuffle(x_train, y_train, random_state=0)\n","x_test, y_test = sklearn.utils.shuffle(x_test, y_test, random_state=0)\n","print('Testing dataset Loading complete.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgqlvUL742Ie"},"source":["x_valid = []\n","y_valid = []\n","for i in labels:\n","    folderPath = os.path.join(os.path.join(base_path,'valid'),i)\n","    for j in tqdm(os.listdir(folderPath)):\n","        img = cv2.imread(os.path.join(folderPath,j))\n","        img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n","        x_valid.append(img)\n","        y_valid.append(i)\n","x_valid = np.array(x_valid)\n","y_valid = np.array(y_valid)\n","x_valid, y_valid = sklearn.utils.shuffle(x_valid, y_valid, random_state=0)\n","\n","print('Valid dataset Loading complete.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iTc82JYsc2ls"},"source":["# One-hot encoding\n","y_train_new = []\n","for i in y_train:\n","    y_train_new.append(labels.index(i))\n","y_train = y_train_new\n","y_train = tf.keras.utils.to_categorical(y_train)\n","\n","\n","y_test_new = []\n","for i in y_test:\n","    y_test_new.append(labels.index(i))\n","y_test = y_test_new\n","y_test = tf.keras.utils.to_categorical(y_test)\n","\n","\n","y_valid_new = []\n","for i in y_valid:\n","    y_valid_new.append(labels.index(i))\n","y_valid = y_valid_new\n","y_valid = tf.keras.utils.to_categorical(y_valid)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JxW-5COemue"},"source":["\n","datagen = ImageDataGenerator(\n","    featurewise_center=False,\n","    samplewise_center=False,\n","    featurewise_std_normalization=False,\n","    samplewise_std_normalization=False,\n","    zca_whitening=False,\n","    rotation_range=30,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    zoom_range=0.2,\n","    horizontal_flip=True, vertical_flip=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SMwnH1YgISw"},"source":["base = ResNet50(weights = 'imagenet',include_top=False,input_shape=(IMAGE_SIZE,IMAGE_SIZE, 3))\n","# Adding Top Layers.\n","model1 = base.output\n","model1 = tf.keras.layers.GlobalAveragePooling2D()(model1)\n","model1 = tf.keras.layers.Dropout(0.5)(model1)\n","model1 = tf.keras.layers.Dense(1024, activation='sigmoid')(model1)\n","model1 = tf.keras.layers.Dense(2, activation = 'sigmoid')(model1)\n","model1 = tf.keras.models.Model(inputs = base.input, outputs = model1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_nER6n7fkwXw"},"source":["# Compiling Model\n","# from keras.optimizers import SGD\n","# opt = SGD(learning_rate=0.01)\n","model1.compile(loss = 'binary_crossentropy', optimizer ='adam', metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ee-PP_5nly4L"},"source":["# Callbacks.\n","tensorboard = TensorBoard(log_dir = 'logs')\n","checkpoint = ModelCheckpoint(\"resnet50.h5\", save_weights_only=True, monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n","reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,mode='auto',verbose=VERBOSE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"asy67dDtmAqG"},"source":["# Fitting the model\n","history1 = model1.fit(x = datagen.flow(x_train, y_train, batch_size = BATCH_SIZE), validation_data=(x_test, y_test), epochs = 20, verbose =VERBOSE, callbacks=[tensorboard,checkpoint,reduce_lr], steps_per_epoch = len(x_train) // BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xr-VEMcA6dRx"},"source":["model1.load_weights('resnet50.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ftvy2Jgv7EHg"},"source":["result1=model1.evaluate(x_valid, y_valid)\n","print(\"Testing Loss :\", result1[0])\n","print(\"Testing Accuracy :\", result1[1]*100, \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbwyITFj7Tzi"},"source":["predictions1 = model1.predict(x_valid)\n","predictions1 = np.argmax(predictions1, axis = 1)\n","y_valid_edit = np.argmax(y_valid , axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5KbyIY-7wtH"},"source":["# Classification report.\n","cf_report = sklearn.metrics.classification_report(y_valid_edit, predictions1)\n","print(cf_report)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JE-SJSLEfLRB"},"source":["epochs = [i for i in range(20)]\n","fig, ax = plt.subplots(1,2)\n","train_acc = history1.history['accuracy']\n","train_loss = history1.history['loss']\n","val_acc = history1.history['val_accuracy']\n","val_loss = history1.history['val_loss']\n","fig.set_size_inches(14, 7)\n","\n","ax[0].plot(epochs, train_acc, 'go-', label = 'Training Accuracy')\n","ax[0].plot(epochs, val_acc, 'ro-', label = 'Validation Accuracy')\n","ax[0].set_title('Training & Validation Accuracy')\n","ax[0].legend()\n","ax[0].set_xlabel('Epochs')\n","ax[0].set_ylabel('Accuracy')\n","\n","ax[1].plot(epochs, train_loss, 'g-o', label ='Training Loss')\n","ax[1].plot(epochs, val_loss, 'r-o', label = 'Validation Loss')\n","ax[1].set_title('Testing Accuracy & Loss')\n","ax[1].legend()\n","ax[1].set_xlabel('Epochs')\n","ax[1].set_ylabel('Training & Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]}]}